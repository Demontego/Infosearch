{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Описание **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Построить графики распределения в спам и не спам множествах следующих признаков:\n",
    "\n",
    "1\tКоличество слов на странице\n",
    "2\tСредняя длинна слова\n",
    "3\tКоличество слов в заголовке страниц (слова в теге <html><head><title> Some text </title>)\n",
    "4\tКоличество слов в анкорах ссылок (<html><body><a> Some text </a>)\n",
    "5\tКоэффициент сжатия\n",
    "\n",
    "Нужно посчитать статистику минимум по трем признакам и обязательно сделать для 1-го и 2-го признаков\n",
    "\n",
    "И отправить первое решение в соревнование https://kaggle.com/join/antispam_infopoisk\n",
    "На основании одного из указанных выше признаков попытаться разделить мн-во, так чтобы score в соревновании был больше 0.55\n",
    "\n",
    "При выполнении всех этих условия в течении семинара +1 балл к ДЗ\n",
    "\n",
    "Описание ДЗ и правил выставления за него баллов в https://inclass.kaggle.com/c/antispam-infopoisk  \n",
    "Сроки ДЗ уточнить у преподователя - обычно 2 недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vkrin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import scipy\n",
    "import binascii\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import base64\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gzip\n",
    "import pymorphy2\n",
    "import zlib\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import importlib\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost\n",
    "import zipfile\n",
    "import gzip\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "from io import BytesIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import namedtuple\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "from bs4.element import Comment\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing.pool import ThreadPool\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACE_NUM = 100\n",
    "import logging\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')\n",
    "\n",
    "def trace(items_num, trace_num=TRACE_NUM):\n",
    "    if items_num % trace_num == 0: logging.info(\"Complete items %05d\" % items_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]'] or isinstance(element, Comment):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    \n",
    "    links = []\n",
    "    links_t=''\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^http://\")}):\n",
    "        links.append(link.get('href'))\n",
    "        links_t+=(' '+link.get_text())\n",
    "    \n",
    "    return ' '.join(visible_texts), links, links_t\n",
    "\n",
    "def tokenize_me(file_text):\n",
    "    tokens = nltk.word_tokenize(file_text)\n",
    "    tokens = [morph.parse(i.lower())[0].normal_form for i in tokens if ( i not in string.punctuation )]\n",
    " \n",
    "    stop_words = stopwords.words('russian')+stopwords.words('english')\n",
    "    stop_words.extend(map(lambda x: x, \n",
    "                          ['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на']))\n",
    "    tokens = [i for i in tokens if ( i not in stop_words )]     \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2text_bs(raw_html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    \"\"\"\n",
    "    Тут производится извлечения из html текста\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    [s.extract() for s in soup(['script', 'style'])]\n",
    "    return soup.get_text()\n",
    "\n",
    "def html2text_title(raw_html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    \"\"\"\n",
    "    Тут производится извлечения title\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    s=soup.find_all('title')\n",
    "    if s:\n",
    "        return tokenize_me(s[0].get_text())\n",
    "    return ''\n",
    "\n",
    "def html2text_ss(raw_html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    \"\"\"\n",
    "    Тут производится извлечения ссылок и анкоров\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    links=[]\n",
    "    texts=''\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "        for text in link.get_text().split():\n",
    "            texts=texts+' '+text\n",
    "    return ' '.join(links),' '.join(tokenize_me(texts))\n",
    "\n",
    "def html2text_bs_visible(raw_html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    \"\"\"\n",
    "    Тут производится извлечения из html текста, который видим пользователю\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")    \n",
    "    [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "    return ' '.join(tokenize_me(soup.get_text()))\n",
    "\n",
    "def html2text_boilerpipe(raw_html):\n",
    "    import boilerpipe\n",
    "    \"\"\"\n",
    "    еще одна библиотека очень хорошо извлекающая именно видимый пользователю текст,\n",
    "    но она завязана на java\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассчет финальных метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    if a == 0: return 0.0\n",
    "    elif b == 0: return 0.0\n",
    "    else: return a/b\n",
    "\n",
    "def calculate_metrics(predictions, threshold):    \n",
    "    \"\"\"\n",
    "    Функция подсчета метрик\n",
    "    Параметры\n",
    "    predictions - ранки по документам\n",
    "    threshold  - порог для метрик\n",
    "    \"\"\"\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    for (url_id, mark, url, prediction) in predictions:        \n",
    "        mark_predict = prediction > threshold\n",
    "\n",
    "        if mark_predict:                     \n",
    "            if mark_predict == mark: true_positive += 1\n",
    "            else: false_positive += 1                    \n",
    "        else:                     \n",
    "            if  mark_predict == mark: true_negative += 1\n",
    "            else: false_negative += 1\n",
    "\n",
    "    class_prec  = safe_divide(true_positive, true_positive + false_positive)\n",
    "    class_recall = safe_divide(true_positive, true_positive + false_negative)\n",
    "        \n",
    "    class_F1 = safe_divide(2 * class_prec * class_recall, class_prec + class_recall)\n",
    "    \n",
    "    \n",
    "    not_class_prec = safe_divide(true_negative, true_negative + false_negative)\n",
    "    not_class_recall = safe_divide(true_negative, true_negative + false_positive)\n",
    "    \n",
    "    not_class_F1 = safe_divide(2 * not_class_prec * not_class_recall, not_class_prec + not_class_recall)\n",
    "    \n",
    "    return ( (class_prec, class_recall, class_F1), (not_class_prec, not_class_recall, not_class_F1) )\n",
    "\n",
    "def arange(start, stop, step):\n",
    "    cur_value = start\n",
    "    while True:\n",
    "        if cur_value > stop: break\n",
    "        yield cur_value\n",
    "        cur_value += step\n",
    "\n",
    "def plot_results(docs, min_threshold=-1, max_threshold=1, step=0.1, trace=False):\n",
    "    x = []\n",
    "    y_p = []\n",
    "    y_n = []\n",
    "    docs_predictions = classifier.predict_all(docs)\n",
    "    for threshold in arange(min_threshold, max_threshold, step):\n",
    "        r = calculate_metrics(docs_predictions, threshold)\n",
    "        x.append(threshold)\n",
    "        y_p.append(r[0])\n",
    "        y_n.append(r[1])        \n",
    "        if trace: \n",
    "            print ('threshold %s',  threshold)\n",
    "            print ('\\tclass_prec %s, class_recall %s, class_F1 %s',  r[0])\n",
    "            print ('\\tnot_class_prec %s, not_class_recall %s, not_class_F1 %s',  r[1])\n",
    "            print ('\\t\\tMacroF1Mesure %s',  ((r[0][2] + r[1][2])/2))\n",
    "    plot_stats(x, y_p, \"Class Result\")\n",
    "    plot_stats(x, y_n, \"Not class Result\")    \n",
    "\n",
    "\n",
    "def plot_stats(x, y, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    prec, = plt.plot( x, \n",
    "                     [k[0] for k in y], \"r\", label='Precision', \n",
    "                     linewidth=1)\n",
    "    accur, = plt.plot( x, \n",
    "                      [k[1] for k in y], \"b\", label='Recall',\n",
    "                      linewidth=1)\n",
    "    f1, =    plt.plot( x, \n",
    "                      [k[2] for k in y], \"g\", label='F1',\n",
    "                      linewidth=1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(handles=[prec, accur, f1])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_features(url, html_data,title=False):\n",
    "    text, links, ankors = text_from_html(html_data)\n",
    "    text=tokenize_me(text)\n",
    "    ankors=tokenize_me(ankors)\n",
    "    all_text=tokenize_me(text) + ' '.join(links)+' '+tokenize_me(ankors)\n",
    "    words = text.split()\n",
    "    words_num = len(words)\n",
    "    ankors_num=len(ankors.split())\n",
    "    urls_num=len(links)\n",
    "    if words_num>0:\n",
    "        uniq=len(set(words))/words_num\n",
    "    else:\n",
    "        uniq=0\n",
    "    len_url=1/len(url)\n",
    "    compression_level = len(gzip.compress(html_data))/len(html_data)\n",
    "    return [len(words), compression_level, all_text, uniq, urls_num,len_url, ankors_num, ankors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocItem = namedtuple('DocItem', ['doc_id', 'is_spam', 'url'])#, 'features'])\n",
    "\n",
    "def load_csv(input_file_name, calc_features_f):    \n",
    "    \"\"\"\n",
    "    Загружаем данные и извлекаем на лету признаки\n",
    "    Сам контент не сохраняется, чтобы уменьшить потребление памяти - чтобы\n",
    "    можно было запускать даже на ноутбуках в классе\n",
    "    \"\"\"\n",
    "    \n",
    "    with gzip.open(input_file_name) if input_file_name.endswith('gz') else open(input_file_name,encoding='utf8')  as input_file:            \n",
    "        headers = input_file.readline()\n",
    "        \n",
    "        for i, line in enumerate(input_file):\n",
    "            trace(i)\n",
    "            parts = line.decode('utf8').strip().split('\\t')\n",
    "            url_id = int(parts[0])                                        \n",
    "            mark = bool(int(parts[1]))                    \n",
    "            url = parts[2]\n",
    "            pageInb64 = parts[3]\n",
    "            html_data = base64.b64decode(pageInb64)\n",
    "            features = calc_features_f(url, html_data)            \n",
    "            yield DocItem(url_id, mark, url, features)            \n",
    "                \n",
    "        trace(i, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "TRAIN_DATA_FILE  = 'kaggle_train_data_tab.csv.gz'\n",
    "TEST_DATA_FILE  = 'kaggle_test_data_tab.csv.gz'\n",
    "\n",
    "train_docs =list(load_csv(TRAIN_DATA_FILE, calc_features))\n",
    "test_docs = list(load_csv(TEST_DATA_FILE, calc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_docs, open('train.p', 'wb'))\n",
    "pickle.dump(test_docs, open('test.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = open('train.p', 'rb')\n",
    "input_test = open('test.p', 'rb')\n",
    "train_docs=pickle.load(input_train)\n",
    "test_docs=pickle.load(input_test)\n",
    "input_test.close()\n",
    "input_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=1.0, min_df=0.001, use_idf=True, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=vectorizer.fit_transform(generator(train_docss=train_docs))\n",
    "X_test=vectorizer.transform(generator(train_docss=test_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=3000\n",
    "voc=set()\n",
    "idx = np.ravel(X_train.sum(axis=0).argsort(axis=1))[::-1][:N]\n",
    "top_words = np.array(vectorizer.get_feature_names())[idx].tolist()\n",
    "for word in top_words:\n",
    "    voc.add(word)\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=[]\n",
    "for doc in train_docs:\n",
    "    f1.append(np.array([np.float64(doc[3][0]),np.float64(doc[3][1]),np.float64(doc[3][3]),np.float64(doc[3][4]),np.float64(doc[3][5]),np.float64(doc[3][6])]))\n",
    "f1=np.array(f1)\n",
    "f2=[]\n",
    "for doc in test_docs:\n",
    "    f2.append(np.array([np.float64(doc[3][0]),np.float64(doc[3][1]),np.float64(doc[3][3]),np.float64(doc[3][4]),np.float64(doc[3][5]),np.float64(doc[3][6])]))\n",
    "f2=np.array(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]\n",
    "for doc in train_docs:\n",
    "    y_train.append(float(doc[1]))\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vs=sparse.csc_matrix(f1).tocsr()\n",
    "X_train_=sparse.hstack([X_train, x_vs]).tocsr()\n",
    "x_vs=sparse.csc_matrix(f2).tocsr()\n",
    "X_test_=sparse.hstack([X_test, x_vs]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train.npy', y_train)\n",
    "scipy.sparse.save_npz('train.npz', X_train_)\n",
    "scipy.sparse.save_npz('test.npz', X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_=scipy.sparse.load_npz('train.npz')\n",
    "X_test_=scipy.sparse.load_npz('test.npz')\n",
    "y_train=np.load('y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y1, y2=train_test_split(X_train_, y_train,  test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = SGDClassifier(alpha=0.0001, average=False,\n",
    "                     class_weight=None,\n",
    "                     early_stopping=False, epsilon=0.1,\n",
    "                     eta0=0.0, fit_intercept=True,\n",
    "                     l1_ratio=0.15,\n",
    "                     learning_rate='optimal',\n",
    "                     max_iter=1000,loss='log',\n",
    "                     n_iter_no_change=5, n_jobs=None,\n",
    "                     penalty='l2', power_t=0.5,\n",
    "                     random_state=None, shuffle=True,\n",
    "                     tol=0.001, validation_fraction=0.1)\n",
    "clf4= xgboost.XGBClassifier(max_depth=6,learning_rate=0.3,n_estimators=1000,scale_pos_weight=1.5, n_jobs=6,probability=True)\n",
    "clf6=SVC(C=1.0, cache_size=200, class_weight=None,\n",
    "                                  coef0=0.0, decision_function_shape='ovr',\n",
    "                                  degree=3, gamma='auto', kernel='rbf',\n",
    "                                  max_iter=-1,\n",
    "                                  random_state=None, shrinking=True, tol=0.001,\n",
    "                                  verbose=False, probability=True)\n",
    "clf7=RandomForestClassifier(n_jobs=6,n_estimators=1000,max_depth=6,class_weight='balanced')\n",
    "clf8=KNeighborsClassifier(n_neighbors=12)\n",
    "clf9=DecisionTreeClassifier(class_weight='balanced')\n",
    "neuronov_v_sloe=[]\n",
    "for j in range(10):\n",
    "    neuronov_v_sloe.append(100)\n",
    "clf10=MLPClassifier(hidden_layer_sizes=neuronov_v_sloe)\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('NB', clf2), ('sgd', clf3),\n",
    "                       ('xgb', clf4), ('svc', clf6), ('rf', clf7),\n",
    "            ('knn', clf8), ('dt', clf9), ('perceptron', clf10)], voting='soft',weights=[1, 1, 1, 2, 1.3, 2, 1,1.3,1.5], n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:58141\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>17.11 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:58141' processes=3 cores=6>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9693251533742332\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    eclf1.fit(x1, y1)\n",
    "\n",
    "y_2=eclf1.predict(x2)\n",
    "print(f1_score(y2,y_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    eclf1.fit(X_train_, y_train)\n",
    "\n",
    "y_pred=eclf1.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"my_submission.csv\", \"wb\")\n",
    "file.write( bytes(str(\"Id,Prediction\\n\"), \"utf-8\"))\n",
    "for i in range(len(test_docs)):\n",
    "    file.write(bytes(str(test_docs[i][0]) + \",\" +str(int(y_pred[i])) + str(\"\\n\"), \"utf-8\"))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### пробовал doc2vec и смотрел косинувское расстояние между документами, но не очень получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[i]) for i,doc in enumerate(generator(train_docss=train_docs+test_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coss=[]\n",
    "cos=[]\n",
    "for i in range(len(train_docs)):\n",
    "    cos.clear()\n",
    "    for j in range(len(train_docs)):\n",
    "        similar_doc = model.docvecs.distance(i,j)\n",
    "        cos.append(similar_doc)\n",
    "    coss.append(cos)\n",
    "    sys.stdout.write('\\r {0}...'.format(i))\n",
    "coss=np.matrix(coss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coss_test=[]\n",
    "cos_test=[]\n",
    "for i in range(len(train_docs),len(test_docs+train_docs)):\n",
    "    cos_test.clear()\n",
    "    for j in range(len(train_docs)):\n",
    "        similar_doc = model.docvecs.distance(i,j)\n",
    "        cos_test.append(similar_doc)\n",
    "    coss_test.append(cos)\n",
    "    sys.stdout.write('\\r {0}...'.format(i))\n",
    "coss_test=np.matrix(coss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('coss_train.npy', coss)\n",
    "np.save('coss_test.npy', coss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vs=sparse.csc_matrix(f1).tocsr()\n",
    "x_cos_train=sparse.csc_matrix(coss).tocsr()\n",
    "X_train_=sparse.hstack([X_train, x_vs]).tocsr()\n",
    "x_vs=sparse.csc_matrix(f2).tocsr()\n",
    "x_cos_test=sparse.csc_matrix(coss_test).tocsr()\n",
    "X_test_=sparse.hstack([X_test, x_vs]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier(max_depth=6,learning_rate=0.3,n_estimators=1000,scale_pos_weight=1.5, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_,y_train)\n",
    "y_pred=model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"my_submission.csv\", \"wb\")\n",
    "file.write( bytes(str(\"Id,Prediction\\n\"), \"utf-8\"))\n",
    "for i in range(len(test_docs)):\n",
    "    file.write(bytes(str(test_docs[i][0]) + \",\" +str(int(y_pred[i])) + str(\"\\n\"), \"utf-8\"))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
