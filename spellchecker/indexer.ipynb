{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import escape\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "from read_queries import read, flatten_list, flatten_dictionary\n",
    "from error_model import ErrorModel\n",
    "from language_model import LanguageModel\n",
    "from bor_tree import BorTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_file = open('queries_all.txt', 'r', encoding='utf-8')\n",
    "queries = queries_file.read()\n",
    "queries = [q.split('\\t') for q in queries]\n",
    "original_queries = []\n",
    "fixed_queries = []\n",
    "for q in queries:\n",
    "    if len(q) == 2:\n",
    "        original_queries.append(q[0])\n",
    "        fixed_queries.append(q[1])\n",
    "    else:\n",
    "        original_queries.append(q[0])\n",
    "        fixed_queries.append(q[0])\n",
    "\n",
    "punctuation = escape(punctuation)\n",
    "\n",
    "fixed_queries_to_words = pd.Series(fixed_queries).replace('[' + punctuation + ']', '', regex=True).str.split()\n",
    "fixed_words = flatten_list(fixed_queries_to_words)\n",
    "\n",
    "\n",
    "original_queries_to_words = pd.Series(original_queries).replace('[' + punctuation + ']', '', regex=True).str.split()\n",
    "original_words = flatten_list(original_queries_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model = ErrorModel()\n",
    "\n",
    "for original, fixed in zip(original_queries_to_words, fixed_queries_to_words):\n",
    "    number_of_words = min(len(original), len(fixed))\n",
    "    for i in range(number_of_words):\n",
    "        error_model.update_statistics(original[i], fixed[i])\n",
    "\n",
    "error_model.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model= LanguageModel()\n",
    "\n",
    "for fixed in fixed_queries_to_words:\n",
    "    for word in fixed:\n",
    "        language_model.update_statistics(word)\n",
    "\n",
    "language_model.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model.store_json('error.json')\n",
    "language_model.store_json('language.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model = ErrorModel()\n",
    "language_model= LanguageModel()\n",
    "error_model.load_json('error.json')\n",
    "language_model.load_json('language.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from re import escape\n",
    "# from string import punctuation\n",
    "# import pandas as pd\n",
    "# from read_queries import read, flatten_list, flatten_dictionary\n",
    "# from error_model import ErrorModel\n",
    "# from language_model import LanguageModel\n",
    "# from bor_tree import BorTree\n",
    "\n",
    "# queries = read('queries_all.txt')\n",
    "# queries = [q.split('\\t') for q in queries]\n",
    "# original_queries = []\n",
    "# fixed_queries = []\n",
    "# for q in queries:\n",
    "#     if len(q) == 2:\n",
    "#         original_queries.append(q[0])\n",
    "#         fixed_queries.append(q[1])\n",
    "#     else:\n",
    "#         original_queries.append(q[0])\n",
    "#         fixed_queries.append(q[0])\n",
    "\n",
    "# punctuation = escape(punctuation)\n",
    "\n",
    "# fixed_queries_to_words = pd.Series(fixed_queries).replace('[' + punctuation + ']', '', regex=True).str.split()\n",
    "# fixed_words = flatten_list(fixed_queries_to_words)\n",
    "\n",
    "\n",
    "# original_queries_to_words = pd.Series(original_queries).replace('[' + punctuation + ']', '', regex=True).str.split()\n",
    "# original_words = flatten_list(original_queries_to_words)\n",
    "\n",
    "# error_model = ErrorModel()\n",
    "\n",
    "# for original, fixed in zip(original_queries_to_words, fixed_queries_to_words):\n",
    "#     number_of_words = min(len(original), len(fixed))\n",
    "#     for i in range(number_of_words):\n",
    "#         error_model.update_statistics(original[i], fixed[i])\n",
    "\n",
    "# error_model.calculate_weights()\n",
    "\n",
    "# language_model= LanguageModel()\n",
    "\n",
    "# for fixed in fixed_queries_to_words:\n",
    "#     for word in fixed:\n",
    "#         language_model.update_statistics(word)\n",
    "\n",
    "# language_model.calculate_weights()\n",
    "\n",
    "# error_model.store_json('error.json')\n",
    "# language_model.store_json('language.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
